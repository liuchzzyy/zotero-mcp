"""
æŠŠ 00_INBOXS_AA ä¸­ç¬¦åˆä»¥ä¸‹ä»»ä¸€æ¡ä»¶çš„å« PDF é™„ä»¶æ¡ç›®ç§»åŠ¨åˆ° 00_AAï¼š
  1. å«æœ‰ä¸¤ä¸ªæˆ–ä»¥ä¸Š PDF é™„ä»¶
  2. å‡ºç‰ˆç¤¾ä¸º Wileyã€RSCã€ACS æˆ– Elsevierï¼ˆå«ä¸€ä¸ª PDFï¼‰
  3. ç»¼è¿°æ–‡ç« ï¼ˆreview articleï¼‰â€”â€”å…ˆå…ƒæ•°æ®å¯å‘å¼ï¼Œä¸ç¡®å®šæ—¶è°ƒç”¨ DeepSeek
  4. å‘è¡¨æ—¶é—´æ—©äº 2000 å¹´

åˆå¹¶è‡ªï¼šmove_dual_pdf_to_aa.py, move_publisher_to_aa.py,
         move_elsevier_to_aa.py, move_to_aa.py
"""
import re
import sys

from openai import OpenAI
from pyzotero import zotero

# â”€â”€ é…ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LIBRARY_ID = "5452188"
API_KEY = "***ZOTERO_API_KEY***"
DEEPSEEK_API_KEY = "***DEEPSEEK_API_KEY***"
DEEPSEEK_BASE_URL = "https://api.deepseek.com"
YEAR_THRESHOLD = 2000

# â”€â”€ ç»¼è¿°è¯†åˆ«å…³é”®è¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
REVIEW_TITLE_KEYWORDS = [
    "review", "overview", "progress", "advances in", "recent advance",
    "perspective", "survey", "roadmap", "state of the art",
]
REVIEW_ABSTRACT_PHRASES = [
    "we review", "this review", "herein we review", "in this review",
    "comprehensive review", "we summarize", "this article reviews",
    "this paper reviews", "we overview", "we present a review",
    "is reviewed", "are reviewed",
]

# â”€â”€ å‡ºç‰ˆç¤¾è¯†åˆ«è§„åˆ™ï¼ˆåŒ¹é… publicationTitle / publisher / extraï¼Œä¸åŒºåˆ†å¤§å°å†™ï¼‰â”€â”€
PUBLISHER_PATTERNS = {
    "Wiley": [
        r"wiley",
        r"angewandte chemie",
        r"advanced materials",
        r"advanced energy materials",
        r"advanced functional materials",
        r"advanced science",
        r"\bsmall\b",
        r"chemsuschem",
        r"chemelectrochem",
        r"chemcatchem",
        r"chemistry[- ]+a european journal",
        r"batteries.*supercaps",
        r"electroanalysis",
        r"european journal of inorganic chemistry",
        r"european journal of organic chemistry",
        r"macromolecular",
    ],
    "RSC": [
        r"royal society of chemistry",
        r"\brsc\b",
        r"journal of materials chemistry",
        r"energy.*environmental science",
        r"physical chemistry chemical physics",
        r"\bnanoscale\b",
        r"green chemistry",
        r"chemical communications",
        r"\bchem\.?\s*comm",
        r"dalton transactions",
        r"rsc advances",
        r"chemical science",
        r"new journal of chemistry",
        r"crystengcomm",
        r"faraday discuss",
        r"materials chemistry frontiers",
        r"journal of the chemical society",
    ],
    "ACS": [
        r"american chemical society",
        r"\bacs\s+\w",
        r"journal of the american chemical society",
        r"\bjacs\b",
        r"nano letters",
        r"chemistry of materials",
        r"journal of physical chemistry",
        r"\blangmuir\b",
        r"inorganic chemistry",
        r"analytical chemistry",
        r"environmental science.*technology",
        r"accounts of chemical research",
        r"crystal growth.*design",
        r"macromolecules",
        r"organometallics",
        r"biochemistry",
        r"the journal of organic chemistry",
        r"industrial.*engineering chemistry",
    ],
    "Elsevier": [
        r"\belsevier\b",
        r"electrochimica acta",
        r"journal of power sources",
        r"journal of electroanalytical chemistry",
        r"chemical engineering journal",
        r"applied surface science",
        r"materials today",
        r"nano energy",
        r"energy storage materials",
        r"journal of alloys and compounds",
        r"ceramics international",
        r"solid state ionics",
        r"carbon",
        r"journal of colloid and interface science",
        r"chemical physics letters",
        r"electrochemistry communications",
        r"international journal of hydrogen energy",
        r"applied energy",
        r"journal of energy storage",
        r"journal of membrane science",
        r"materials letters",
        r"scripta materialia",
        r"acta materialia",
        r"journal of solid state chemistry",
        r"coordination chemistry reviews",
        r"progress in natural science",
        r"chinese chemical letters",
        r"journal of hazardous materials",
        r"chemosphere",
    ],
}

# ç¼–è¯‘æ­£åˆ™
COMPILED = {
    pub: [re.compile(p, re.IGNORECASE) for p in patterns]
    for pub, patterns in PUBLISHER_PATTERNS.items()
}


# â”€â”€ å·¥å…·å‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_year(item: dict) -> int | None:
    date_str = item["data"].get("date", "")
    m = re.search(r"\b(1[5-9]\d\d|20\d\d)\b", date_str)
    return int(m.group(1)) if m else None


def detect_publisher(item: dict) -> tuple[str | None, str | None]:
    """è¿”å› (å‡ºç‰ˆç¤¾å, åŒ¹é…å­—æ®µ)ï¼ŒåŒ¹é…ä¸åˆ°è¿”å› (None, None)ã€‚"""
    fields = [
        item["data"].get("publicationTitle", ""),
        item["data"].get("publisher", ""),
        item["data"].get("extra", ""),
    ]
    text = " | ".join(fields)
    for pub, regexes in COMPILED.items():
        for rx in regexes:
            if rx.search(text):
                matched = (item["data"].get("publicationTitle")
                           or item["data"].get("publisher", ""))
                return pub, matched[:50]
    return None, None


def is_review_by_metadata(item: dict) -> tuple[bool, str | None]:
    """å…ƒæ•°æ®å¯å‘å¼åˆ¤æ–­æ˜¯å¦ä¸ºç»¼è¿°ï¼Œä¸ç¡®å®šåˆ™è¿”å› (False, None)ã€‚"""
    title = item["data"].get("title", "").lower()
    extra = item["data"].get("extra", "").lower()
    abstract = item["data"].get("abstractNote", "").lower()

    if re.search(r"\btype\s*:\s*review\b", extra):
        return True, "extra: Type=Review"

    for kw in REVIEW_TITLE_KEYWORDS:
        if kw in title:
            return True, f"æ ‡é¢˜å« '{kw}'"

    snippet = abstract[:400]
    for phrase in REVIEW_ABSTRACT_PHRASES:
        if phrase in snippet:
            return True, f"æ‘˜è¦å« '{phrase}'"

    journal = item["data"].get("publicationTitle", "").lower()
    if "review" in journal or "reviews" in journal:
        return True, f"æœŸåˆŠåå« review ({journal[:40]})"

    return False, None


def is_review_by_deepseek(item: dict, client: OpenAI) -> bool:
    """è°ƒç”¨ DeepSeek åˆ¤æ–­æ˜¯å¦ä¸ºç»¼è¿°ï¼ˆä»…åœ¨å…ƒæ•°æ®æ— æ³•ç¡®å®šæ—¶ä½¿ç”¨ï¼‰ã€‚"""
    title = item["data"].get("title", "ï¼ˆæ— æ ‡é¢˜ï¼‰")
    abstract = item["data"].get("abstractNote", "")
    journal = item["data"].get("publicationTitle", "")
    year = extract_year(item)

    prompt = (
        "åˆ¤æ–­ä¸‹é¢è¿™ç¯‡æ–‡ç« æ˜¯å¦æ˜¯ç»¼è¿°æ–‡ç« ï¼ˆreview articleï¼‰ã€‚\n"
        "ç»¼è¿°çš„ç‰¹å¾ï¼šç³»ç»Ÿå›é¡¾æŸé¢†åŸŸç ”ç©¶è¿›å±•ï¼Œæ€»ç»“å¤šç¯‡æ–‡çŒ®ï¼Œé€šå¸¸æ— åŸåˆ›å®éªŒæ•°æ®ã€‚\n\n"
        f"æ ‡é¢˜ï¼š{title}\n"
        f"æœŸåˆŠï¼š{journal}\n"
        f"å¹´ä»½ï¼š{year}\n"
        f"æ‘˜è¦ï¼š{abstract[:600] if abstract else 'ï¼ˆæ— æ‘˜è¦ï¼‰'}\n\n"
        "åªå›ç­” YES æˆ– NOï¼Œä¸è¦è§£é‡Šã€‚"
    )
    try:
        resp = client.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=5,
            temperature=0,
        )
        answer = resp.choices[0].message.content.strip().upper()
        return "YES" in answer
    except Exception as e:
        print(f"    âš ï¸  DeepSeek è°ƒç”¨å¤±è´¥: {e}")
        return False


def move_item(zot, item: dict, inbox_key: str, aa_key: str) -> bool:
    current_cols = item["data"].get("collections", [])
    new_cols = list(set(current_cols + [aa_key]) - {inbox_key})
    try:
        zot.update_item({
            "key": item["key"],
            "version": item["version"],
            "collections": new_cols,
        })
        return True
    except Exception as e:
        print(f"    âŒ ç§»åŠ¨å¤±è´¥: {e}")
        return False


# â”€â”€ ä¸»æµç¨‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    zot = zotero.Zotero(LIBRARY_ID, "user", API_KEY)
    deepseek = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=DEEPSEEK_BASE_URL)

    # 1. è·å– collections
    print("æ­£åœ¨è·å– collections...")
    col_map = {c["data"]["name"]: c["key"]
               for c in zot.everything(zot.collections())}
    inbox_key = col_map.get("00_INBOXS_AA")
    aa_key = col_map.get("00_AA")
    if not inbox_key or not aa_key:
        sys.exit(f"âŒ æ‰¾ä¸åˆ°æ‰€éœ€ collectionã€‚ç°æœ‰: {sorted(col_map.keys())}")
    print(f"âœ… 00_INBOXS_AA={inbox_key}, 00_AA={aa_key}\n")

    # 2. è·å–æ‰€æœ‰éé™„ä»¶/éç¬”è®°æ¡ç›®
    print("æ­£åœ¨è·å–æ¡ç›®...")
    raw = zot.everything(zot.collection_items(inbox_key, itemType="-attachment"))
    items = [i for i in raw if i["data"].get("itemType") != "note"]
    total = len(items)
    print(f"å…± {total} ä¸ªæ¡ç›®\n{'â”€'*65}")

    results = {"moved": [], "skipped_no_pdf": [], "skipped_no_match": []}
    deepseek_calls = 0

    for i, item in enumerate(items, 1):
        key = item["key"]
        title = item["data"].get("title", "(æ— æ ‡é¢˜)")[:55]
        prefix = f"[{i:3d}/{total}]"

        # è·å– PDF é™„ä»¶
        children = zot.children(key)
        pdfs = [c for c in children
                if c["data"].get("itemType") == "attachment"
                and c["data"].get("contentType") == "application/pdf"]
        pdf_count = len(pdfs)

        if pdf_count == 0:
            print(f"{prefix} â­ï¸  æ— PDFï¼Œè·³è¿‡: {title}")
            results["skipped_no_pdf"].append(key)
            continue

        reason = None

        # æ¡ä»¶ 1ï¼šä¸¤ä¸ªæˆ–ä»¥ä¸Š PDF
        if pdf_count >= 2:
            reason = f"{pdf_count} ä¸ªPDF"

        # æ¡ä»¶ 4ï¼šå‘è¡¨æ—¶é—´æ—©äº 2000
        if reason is None:
            year = extract_year(item)
            if year is not None and year < YEAR_THRESHOLD:
                reason = f"å‘è¡¨äº {year} å¹´"

        # æ¡ä»¶ 2ï¼šå‡ºç‰ˆç¤¾åŒ¹é…ï¼ˆWiley / RSC / ACS / Elsevierï¼‰
        if reason is None:
            pub, journal = detect_publisher(item)
            if pub:
                reason = f"{pub} ({journal})"

        # æ¡ä»¶ 3ï¼šç»¼è¿°æ–‡ç« ï¼ˆå…ƒæ•°æ® â†’ DeepSeekï¼‰
        if reason is None:
            is_rev, meta_reason = is_review_by_metadata(item)
            if is_rev:
                reason = f"ç»¼è¿°ï¼ˆ{meta_reason}ï¼‰"
            else:
                print(f"{prefix} ğŸ¤– DeepSeek åˆ¤æ–­ä¸­: {title}")
                deepseek_calls += 1
                if is_review_by_deepseek(item, deepseek):
                    reason = "ç»¼è¿°ï¼ˆDeepSeekï¼‰"

        if reason:
            print(f"{prefix} âœ… ã€{reason}ã€‘: {title}")
            ok = move_item(zot, item, inbox_key, aa_key)
            if ok:
                results["moved"].append((key, title, reason))
        else:
            print(f"{prefix} â– ä¸ç¬¦åˆæ¡ä»¶: {title}")
            results["skipped_no_match"].append(key)

    # æ±‡æ€»
    print(f"\n{'â•'*65}")
    print(f"å®Œæˆï¼DeepSeek å…±è°ƒç”¨ {deepseek_calls} æ¬¡")
    print(f"  âœ… å·²ç§»åŠ¨åˆ° 00_AA : {len(results['moved'])} æ¡")
    print(f"  â­ï¸  æ— PDFè·³è¿‡     : {len(results['skipped_no_pdf'])} æ¡")
    print(f"  â– ä¸ç¬¦åˆæ¡ä»¶    : {len(results['skipped_no_match'])} æ¡")

    if results["moved"]:
        print("\nç§»åŠ¨æ˜ç»†ï¼š")
        for key, title, reason in results["moved"]:
            print(f"  {key}  [{reason}]  {title}")


if __name__ == "__main__":
    main()
